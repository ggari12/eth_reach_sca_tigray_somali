---
title: "ETH SCA Tigray, Somali: Data Collection Tracker"
author: "REACH"
date: "February 2024"
output:
    html_document:
    toc: true
toc_float:
    collapsed: false
smooth_scroll: false
knit: (function(inputFile, encoding) {rmarkdown::render(inputFile, encoding = encoding, output_file = paste0(dirname(inputFile), '/eth_sca_tigray_somali_data_collection_tracker_', format(Sys.Date(), '%Y_%m_%d'),'.html')) })
---
    
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
# read packages
library(tidyverse)
library(lubridate)
library(glue)
library(htmlwidgets)
library(supporteR)
library(leaflet)

# read data
df_tool_data <- readxl::read_excel("../inputs/ETH2306a_SCA_Tigray_Somali_data.xlsx")  |>  
  mutate(uuid = `_uuid`,
         start_date = as_date(start),
         start = as_datetime(start),
         end = as_datetime(end),
         latitude = as.numeric(`_gps_latitude`),
         longitude = as.numeric(`_gps_longitude`))

# days that contain data
df_days_for_data_collection <- df_tool_data |> 
  select(start_date) |> 
  unique() |> 
  arrange(start_date) |> 
  pull()

# cleaning log handling
df_data_support_cl_log <- df_tool_data |> 
  select(uuid, zone, woreda, latitude, longitude)

df_cl_log <- read_csv(file = "../inputs/combined_checks_eth_sca_tigray_somali.csv") |> 
  left_join(df_data_support_cl_log |> select(-woreda), by = "uuid")

# change_response logs that affect stats in the data collection progress
cl_log_change_response <- df_cl_log |> 
  filter(type == "change_response", 
         !is.na(value),
         reviewed == 1, 
         adjust_log != "delete_log", 
  ) |> 
  select(uuid, name, value)

# updated tool data
df_updated_tool_data <- df_tool_data

# get uuids from cleaning log
uuids_chg_response <- cl_log_change_response |> pull(uuid) |> unique()

for (current_uuid in uuids_chg_response) {
  current_uuid_data <- cl_log_change_response |> 
    filter(uuid == current_uuid) |> 
    mutate(value = ifelse(name == "enumerator_id", as.numeric(value), value)) |> 
    pivot_wider(names_from = "name", values_from = "value", uuid)
  print(current_uuid_data)
  # process current updates
  df_current_updated <- df_updated_tool_data |> 
    rows_update(y = current_uuid_data, by = "uuid")
  # update the parent dataset with current updates
  df_updated_tool_data <- df_current_updated
}

# enumerator performance data
df_enum_performance <- df_updated_tool_data |> 
  mutate(int.survey_time_interval = lubridate::time_length(end - start, unit = "min"),
         int.survey_time_interval = ceiling(int.survey_time_interval))

# surveys for deletion
df_cl_deletion <- df_cl_log |> 
  filter(type %in% "remove_survey", reviewed == 1, !adjust_log %in% "delete_log") |>
  distinct(woreda, uuid)

df_cl_surveys_for_deletion <- df_cl_deletion |>
  group_by(woreda) |>
  summarise(surveys_for_deletion = n())

# sample data(estmated)
df_education_samples <- readxl::read_excel("../support_files/sca_sample_size.xlsx", sheet = "education") |> 
    select(woreda, facility_assessed, required_samples = est_sample_size)

df_health_samples <- readxl::read_excel("../support_files/sca_sample_size.xlsx", sheet = "health") |> 
    select(woreda, facility_assessed, required_samples = est_sample_size)

df_water_points_samples <- readxl::read_excel("../support_files/sca_sample_size.xlsx", sheet = "water_point") |> 
    select(woreda, facility_assessed, required_samples = est_sample_size)

# tool
loc_tool <- "../inputs/ETH2306a_SCA_Tigray_Somali_tool.xlsx"

df_survey <- readxl::read_excel(loc_tool, sheet = "survey")
df_choices <- readxl::read_excel(loc_tool, sheet = "choices") |> 
  mutate(code = name, label = `label::English`)

# extract location labels
df_region_info <- df_choices |> 
  filter(list_name %in% c("region")) |> 
  select(code, region = label)
df_zone_info <- df_choices |> 
  filter(list_name %in% c("zone")) |> 
  select(code, zone = label)
df_woreda_info <- df_choices |> 
  filter(list_name %in% c("woreda")) |> 
  select(code, woreda = label)

# region_to_woreda_info
df_region_to_woreda_info <- df_choices |> 
  filter(list_name %in% c("woreda")) |> 
  select(region_code = region, zone_code = zone, code, woreda = label) |> 
  left_join(df_region_info, by = c("region_code" = "code")) |>
  relocate(region, .after = region_code) |>
  left_join(df_zone_info, by = c("zone_code" = "code")) |>
  relocate(zone, .after = zone_code) |>
  select(-c(region_code, zone_code))

# functions for changing some options in the table
dt_options_fewcols <- function(x){
  DT::datatable(x,
                rownames = FALSE,
                options = list(
                  pageLength = 12,
                  initComplete = JS(
                    "function(settings, json) {",
                    "$(this.api().table().header()).css({'background-color': '#333', 'color': '#fff'});",
                    "}")
          )
  )
}
```

## Summary on the surveys done

> Tigray: Total number of collected surveys **`r df_updated_tool_data %>% filter(region == "ET01") %>% nrow()`**\
Somali: Total number of collected surveys **`r df_updated_tool_data %>% filter(region == "ET05") %>% nrow()`**\
Surveys for deletion: **`r nrow(df_cl_deletion)`**,\
Last date of data collection: **`r df_days_for_data_collection[length(df_days_for_data_collection)]`**.

### Summary on the surveys per location by facility assessed

### Education Facility: **`r df_updated_tool_data %>% filter(facility_assessed == "education") %>% nrow()`** surveys

```{r, echo = FALSE}
df_samp_per_location <- df_education_samples
df_updated_tool_data |> 
  filter(facility_assessed == "education") |> 
  group_by(woreda) |> 
  summarise(number_of_surveys = n()) |> 
  arrange(woreda) |> 
  full_join(df_samp_per_location, by = c("woreda" = "woreda")) |>
  mutate(required_samples = ifelse(is.na(required_samples), 0, required_samples)) |> 
  left_join(df_cl_surveys_for_deletion, by = "woreda") |> 
  mutate(number_of_surveys = ifelse(is.na(number_of_surveys), 0, number_of_surveys),
         surveys_for_deletion = ifelse(is.na(surveys_for_deletion), 0, surveys_for_deletion),
         int.surveys_and_deletion = number_of_surveys - surveys_for_deletion,
         remaining_surveys = required_samples - int.surveys_and_deletion ) |> 
  select(-c(int.surveys_and_deletion, facility_assessed)) |> 
  mutate(woreda = as.character(woreda)) |> 
  left_join(df_region_to_woreda_info, by = c("woreda" = "code")) |> 
  select(-c(region)) |> 
  relocate(c(zone, woreda, woreda.y), .before = number_of_surveys) |>
  dt_options_fewcols()
```

### Health Facility: **`r df_updated_tool_data %>% filter(facility_assessed == "health") %>% nrow()`** surveys

```{r, echo = FALSE}
df_samp_per_location <- df_health_samples
df_updated_tool_data |> 
  filter(facility_assessed == "health") |> 
  group_by(woreda) |> 
  summarise(number_of_surveys = n()) |> 
  arrange(woreda) |> 
  full_join(df_samp_per_location, by = c("woreda" = "woreda")) |>
  mutate(required_samples = ifelse(is.na(required_samples), 0, required_samples)) |> 
  left_join(df_cl_surveys_for_deletion, by = "woreda") |> 
  mutate(number_of_surveys = ifelse(is.na(number_of_surveys), 0, number_of_surveys),
         surveys_for_deletion = ifelse(is.na(surveys_for_deletion), 0, surveys_for_deletion),
         int.surveys_and_deletion = number_of_surveys - surveys_for_deletion,
         remaining_surveys = required_samples - int.surveys_and_deletion ) |> 
  select(-c(int.surveys_and_deletion, facility_assessed)) |> 
  mutate(woreda = as.character(woreda)) |> 
  left_join(df_region_to_woreda_info, by = c("woreda" = "code")) |> 
  select(-c(region)) |> 
  relocate(c(zone, woreda, woreda.y), .before = number_of_surveys) |>
  dt_options_fewcols()
```

### Water points Facility: **`r df_updated_tool_data %>% filter(facility_assessed == "water_point") %>% nrow()`** surveys

```{r, echo = FALSE}
df_samp_per_location <- df_water_points_samples
df_updated_tool_data |> 
  filter(facility_assessed == "water_point") |> 
  group_by(woreda) |> 
  summarise(number_of_surveys = n()) |> 
  arrange(woreda) |> 
  full_join(df_samp_per_location, by = c("woreda" = "woreda")) |>
  mutate(required_samples = ifelse(is.na(required_samples), 0, required_samples)) |> 
  left_join(df_cl_surveys_for_deletion, by = "woreda") |> 
  mutate(number_of_surveys = ifelse(is.na(number_of_surveys), 0, number_of_surveys),
         surveys_for_deletion = ifelse(is.na(surveys_for_deletion), 0, surveys_for_deletion),
         int.surveys_and_deletion = number_of_surveys - surveys_for_deletion,
         remaining_surveys = required_samples - int.surveys_and_deletion ) |> 
  select(-c(int.surveys_and_deletion, facility_assessed)) |> 
  mutate(woreda = as.character(woreda)) |> 
  left_join(df_region_to_woreda_info, by = c("woreda" = "code")) |> 
  select(-c(region)) |> 
  relocate(c(zone, woreda, woreda.y), .before = number_of_surveys) |>
  dt_options_fewcols()
```

### Daily enumerator performance

The average survey time for all the data is: **`r get_average_survey_time(df_updated_tool_data)`** Minutes

```{r, echo = FALSE}
df_enum_performance |> 
group_by(region, zone, woreda, start_date, enumerator_id) |>
  summarise(number_of_interviews_done = n(), `average_survey_time(minutes)` = round(mean(int.survey_time_interval, na.rm = TRUE), 0)) |> 
  #left_join(df_region_info, by = c("region" = "code")) |> 
  #relocate(region, .after = region) |> 
  #left_join(df_zone_info, by = c("zone" = "code")) |> 
  #relocate(zone, .after = zone) |>
  #mutate(woreda = as.character(woreda)) |> 
  #left_join(df_woreda_info, by = c("woreda" = "code")) |> 
  #relocate(woreda, .after = woreda) |>
  ungroup() |> 
  select(-(region)) |> 
  dt_options_fewcols()
```

## Looking into the cleaning log:

### a) Number of issues by issue_id

```{r, echo = FALSE}
df_cl_log |> 
  group_by(issue_id) |> 
  summarise(number_of_issues_by_issue_id = n()) |>
  # mutate(int.issue_id = str_extract(string = issue_id, pattern = "[0-9]{1,3}")) |> 
  # left_join(df_logical_check_description, by = c("int.issue_id" = "check_number")) |> 
  # mutate(issue = ifelse(str_detect(string = issue_id, pattern = "[0-9]{1,3}"), check_description, issue_id)) |> 
  # select(-c(int.issue_id, check_description))  |> 
  dt_options_fewcols()
```

### b) Number of issues by enumerator

```{r, echo = FALSE}
df_cl_log |> 
  group_by(enumerator_id) |> 
  summarise(number_of_issues_by_enumerator_id = n()) |>
  dt_options_fewcols()
```

### c) Number of issues by enumerator and issue_id

```{r, echo = FALSE}
df_cl_log |> 
  group_by(enumerator_id, issue_id) |> 
  summarise(number_of_issues_by_enumerator_and_issue_id = n()) |>
  # mutate(int.issue_id = str_extract(string = issue_id, pattern = "[0-9]{1,3}")) |> 
  # left_join(df_logical_check_description, by = c("int.issue_id" = "check_number")) |> 
  # mutate(issue = ifelse(str_detect(string = issue_id, pattern = "[0-9]{1,3}"), check_description, issue_id)) |> 
  # select(-c(int.issue_id, check_description))  |> 
  dt_options_fewcols()
```

### d) Enumerators with surveys for deletion

```{r, echo = FALSE}
df_cl_log |> 
  filter(type %in% c("remove_survey"), reviewed == 1, !adjust_log %in% c("delete_log")) |> 
  group_by(enumerator_id) |> 
  summarise(number_of_surveys_for_deletion_by_enumerator = n()) |>
  dt_options_fewcols()
```

### e) Map of surveys for deletion

```{r, echo = FALSE, out.width="100%"}
# popup
labels_pts <- ~sprintf(
    "<strong>Issue ID :  <strong>%s</strong><br/>
      Issue :  <strong>%s</strong><br/>
      Enumerator ID :  <strong>%s</strong>",
    issue_id, issue, enumerator_id) |> 
    lapply(htmltools::HTML)

df_cl_log |> 
    filter(type == "remove_survey", reviewed == 1, !adjust_log %in% c("delete_log")) |> 
    group_by(uuid, woreda, latitude, longitude) |> 
    summarise(start_date = paste(start_date, collapse = " : "),
              enumerator_id = paste(enumerator_id, collapse = " : "),
              type = paste(type, collapse = " : "),
              name = paste(name, collapse = " : "),
              current_value = paste(current_value, collapse = " : "),
              value = paste(value, collapse = " : "),
              issue_id = paste(issue_id, collapse = " : "),
              issue = paste(issue, collapse = " : ")) |> 
    unique() |>  
    leaflet() |> 
    addTiles() |>
    addCircleMarkers(~longitude,
                     ~latitude,
                     popup = labels_pts,
                     radius = 10,
                     color = "red",
                     stroke = FALSE, fillOpacity = 0.9,
                     label = labels_pts,
                     clusterOptions = markerClusterOptions())
```

**NB:** *required_samples* this number used ONLY for data monitoring purpose (might be vary based on the facilities assessed by team during data collection).